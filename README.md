# scratch-pytorch-step-by-step

本项目会一步步教你实现语法风格类似pytorch的深度学习框架，众所周知pytorch实际上是靠C语言实现的底层函数，再用python和底层函数绑定。考虑到太过于还原可能会增加学习门槛（主要本人不太会），本教程会用python的基础语法和numpy实现深度学习领域的一些基础算法，包括反向传播，随机梯度下降，Adam优化器，Dropout层等。实现的模型包括CNN, RNN, LSTM, ResNet, transformer等。

## 目录

| 章节 | 内容                                                                        | 完成度 |
| ---- | --------------------------------------------------------------------------- | ------ |
| 1.1  | Python的基本数据类型                                                        | ✅     |
| 1.2  | Python中的条件控制语句                                                      | ✅     |
| 1.3  | Python中的函数和类的声明和使用                                              | ✅     |
| 1.4  | Numpy这个Python包的用法                                                     | ✅     |
| 2.1  | 用线性回归的方式拟合一个曲线，均方差损失函数                                | ✅     |
| 2.2  | 实现张量的基本计算，sigmoid，tanh，relu激活函数，反向传播算法，随机梯度下降 | ✅     |
| 2.3  | 将张量的支持范围扩充到矩阵，Adam梯度下降，网络模型的可视化                  | ✅     |
| 2.4  | 全连接网络模型，模型信息打印                                                | ✅     |
| 3.1  | 卷积神经网络，卷积层，池化层，Dropout层                                     | ⬜     |
| 3.2  | AlexNet网络的实现                                                           | ⬜     |
| 3.3  | 矩阵拼接，循环神经网络的实现                                                | ✅     |
| 3.4  | 长短期记忆网络的实现                                                        | ✅     |
| 3.5  | 残差网络的实现                                                              | ✅     |
| 3.6  | 用pytorch从头到尾实现transformer模型                                        | ✅     |
| 3.7  | 用mytorch从头到位实现transformer模型                                        | ⬜     |
| 3.8  | 实现mamba模型                                                               | ⬜     |
