{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4 线性模型和全连接神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本节，我们会介绍一种最基本的神经网络模型，全连接神经网络，其实在之前的几节，我们所实现的就是全连接神经网络，但是在本节我们会用pytorch的风格实现Module类，实现更方便的构建模型的函数，同时我们会介绍何为欠拟合，过拟合，以及一些消除欠拟合过拟合的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们首先把我们在张量这几节中实现的内容放到一个py文件中，方便我们之后的调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mytorch import Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们先实现Module类，这个类会是所有模型的夫类，主要实现了模型结构的定义，参数的初始化，同时记录和追踪模型的参数变化，当你没有定义模型前向传播的方法的时候，会报错，因为python中没有借口，我们用raise来表示，让每个子类保证实现了forward方法，同时我们希望这个类的实例被调用时，自带运行forward来求解，所以实现了\\_\\_call\\_\\_方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module:\n",
    "    def __init__(self):\n",
    "        self._parameters = {}\n",
    "        self._modules = {}\n",
    "    def forward(self, *input):\n",
    "        raise NotImplementedError\n",
    "    def __call__(self, *input):\n",
    "        return self.forward(*input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们来实现一个简单的线性模型，测试我们的Module类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class Linear(Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.w = Tensor.from_numpy(np.random.rand(in_features, out_features))\n",
    "        self.b = Tensor.from_numpy(np.random.rand(1, out_features))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x*self.w+self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(data=[[3.42376874 3.12571958 2.25732465 2.44523259 2.78703212]], grad=[[0. 0. 0. 0. 0.]], trainable=True)\n"
     ]
    }
   ],
   "source": [
    "in_features = 10\n",
    "out_features = 5\n",
    "\n",
    "linear_layer = Linear(in_features, out_features)\n",
    "x = Tensor.from_numpy(np.random.rand(1, in_features))\n",
    "output = linear_layer(x)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们希望实现named_parameters方法，这个方法会记录这个模型的各层的形状和数值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\_\\_setattr\\_\\_ 是一个特殊方法（或称魔术方法）在 Python 中，用于拦截对对象属性的赋值操作。当你试图给对象的一个属性赋值时，这个方法会被自动调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Value must be positive",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, value)\n\u001b[1;32m     10\u001b[0m obj \u001b[38;5;241m=\u001b[39m PositiveNumber(\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m obj\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m10\u001b[39m\n",
      "Cell \u001b[0;32mIn[24], line 7\u001b[0m, in \u001b[0;36mPositiveNumber.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, value):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m value \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m----> 7\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValue must be positive\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, value)\n",
      "\u001b[0;31mValueError\u001b[0m: Value must be positive"
     ]
    }
   ],
   "source": [
    "class PositiveNumber:\n",
    "    def __init__(self, initial_value):\n",
    "        self.value = initial_value\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        if name == 'value' and value < 0:\n",
    "            raise ValueError(\"Value must be positive\")\n",
    "        object.__setattr__(self, name, value)\n",
    "\n",
    "obj = PositiveNumber(5)\n",
    "obj.value = -10  # 这会触发 ValueError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们会用\\_\\_setattr\\_\\_及时更新parameters和modules列表，然后通过调用named_parameters打印参数列表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " object.\\_\\_setattr\\_\\_(self, name, value) 用于在对象中设置一个属性。在 Python 中，当我们为一个对象设置属性时，如 self.attribute = value，实际上是在调用该对象的 \\_\\_setattr\\_\\_ 方法。但在我们自定义的 \\_\\_setattr\\_\\_ 方法中，如果直接使用 self.attribute = value，这会再次触发 \\_\\_setattr\\_\\_，从而导致无限递归。为了避免这种情况，在自定义的 \\_\\_setattr\\_\\_ 方法中设置属性时，我们应该使用基类（在这种情况下是 object 类）的 \\_\\_setattr\\_\\_ 方法。这样做可以直接在对象上设置属性，而不会再次触发 \\_\\_setattr\\_\\_。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module:\n",
    "    def __init__(self):\n",
    "        self._parameters = {}\n",
    "        self._modules = {}\n",
    "\n",
    "    def forward(self, *input):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __call__(self, *input):\n",
    "        return self.forward(*input)\n",
    "\n",
    "    def named_parameters(self, memo=None, prefix=''):\n",
    "        if memo is None:\n",
    "            memo = set()\n",
    "\n",
    "        for name, param in self._parameters.items():\n",
    "            if param not in memo:\n",
    "                memo.add(param)\n",
    "                yield prefix + name, param\n",
    "\n",
    "        for name, mod in self._modules.items():\n",
    "            submodule_prefix = prefix + name + '.'\n",
    "            for name, param in mod.named_parameters(memo, submodule_prefix):\n",
    "                yield name, param\n",
    "\n",
    "    def add_module(self, name, module):\n",
    "        if not isinstance(module, Module) and module is not None:\n",
    "            raise TypeError(\"{} is not a Module subclass\".format(type(module)))\n",
    "        self._modules[name] = module\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        if isinstance(value, Tensor):\n",
    "            object.__setattr__(self, name, value)  # 先设置属性\n",
    "            self._parameters[name] = value          # 然后添加到参数字典中\n",
    "        elif isinstance(value, Module):\n",
    "            self.add_module(name, value)\n",
    "        else:\n",
    "            object.__setattr__(self, name, value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们再来测试一下Linear这个类的参数列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.w = Tensor.from_numpy(np.random.rand(in_features, out_features))\n",
    "        self.b = Tensor.from_numpy(np.random.rand(1, out_features))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x*self.w+self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w Tensor(data=[[0.28560691 0.8672992  0.88595457 0.11899527 0.80321621]\n",
      " [0.33203469 0.50307607 0.952864   0.36840301 0.2706384 ]\n",
      " [0.97381182 0.42024134 0.49264617 0.38794506 0.59529725]\n",
      " [0.08387362 0.30237794 0.26447564 0.93845391 0.16128597]\n",
      " [0.40830442 0.53959658 0.50127377 0.21927836 0.40006681]\n",
      " [0.58827379 0.74123641 0.43745427 0.13590099 0.01242012]\n",
      " [0.43069382 0.59793469 0.20412198 0.08868851 0.90757201]\n",
      " [0.90974848 0.84735987 0.02955181 0.62218034 0.69052233]\n",
      " [0.86024293 0.16520478 0.07021213 0.7879401  0.93634434]\n",
      " [0.51618515 0.21954381 0.40886429 0.09486535 0.58629152]], grad=[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]], trainable=True)\n",
      "b Tensor(data=[[0.53476514 0.53942268 0.36438901 0.44903074 0.13865316]], grad=[[0. 0. 0. 0. 0.]], trainable=True)\n"
     ]
    }
   ],
   "source": [
    "for name, parameter in linear_layer.named_parameters():\n",
    "    print(name, parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module()\n"
     ]
    }
   ],
   "source": [
    "print(linear_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，我们完成\\_\\_repr\\_\\_方法，来自动打印模型的网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module:\n",
    "    def __init__(self):\n",
    "        self._parameters = {}\n",
    "        self._modules = {}\n",
    "\n",
    "    def forward(self, *input):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __call__(self, *input):\n",
    "        return self.forward(*input)\n",
    "\n",
    "    def named_parameters(self, memo=None, prefix=''):\n",
    "        if memo is None:\n",
    "            memo = set()\n",
    "\n",
    "        for name, param in self._parameters.items():\n",
    "            if param not in memo:\n",
    "                memo.add(param)\n",
    "                yield prefix + name, param\n",
    "\n",
    "        for name, mod in self._modules.items():\n",
    "            submodule_prefix = prefix + name + '.'\n",
    "            for name, param in mod.named_parameters(memo, submodule_prefix):\n",
    "                yield name, param\n",
    "\n",
    "    def add_module(self, name, module):\n",
    "        if not isinstance(module, Module) and module is not None:\n",
    "            raise TypeError(\"{} is not a Module subclass\".format(type(module)))\n",
    "        self._modules[name] = module\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        if isinstance(value, Tensor):\n",
    "            object.__setattr__(self, name, value)  # 先设置属性\n",
    "            self._parameters[name] = value          # 然后添加到参数字典中\n",
    "        elif isinstance(value, Module):\n",
    "            object.__setattr__(self, name, value)\n",
    "            self.add_module(name, value)\n",
    "        else:\n",
    "            object.__setattr__(self, name, value)\n",
    "\n",
    "    def __repr__(self):\n",
    "        lines = [self.__class__.__name__ + '(']\n",
    "        for name, module in self._modules.items():\n",
    "            mod_str = repr(module).replace('\\n', '\\n  ')\n",
    "            lines.append(f\"  ({name}): {mod_str}\")\n",
    "        lines.append(')')\n",
    "        return '\\n'.join(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们再对Linear类进行简单的修改，让其变成我们的标准模型类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Module):\n",
    "    def __init__(self, in_features, out_features, bias = True):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.bias = bias\n",
    "        self.w = Tensor.from_numpy(np.random.rand(in_features, out_features))\n",
    "        if bias:\n",
    "            self.b = Tensor.from_numpy(np.random.rand(1, out_features))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x*self.w+self.b if self.bias else x*self.w\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Linear(in_features={self.in_features}, out_features={self.out_features}, bias={self.bias})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = Linear(5,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(data=[[1.98412438 1.91935529 1.0297541  1.74943314 1.28147485 0.85292096]], grad=[[0. 0. 0. 0. 0. 0.]], trainable=True)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l(Tensor.from_numpy(np.random.rand(1, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=5, out_features=6, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = Linear(5,6)\n",
    "        self.l2 = Linear(6,8)\n",
    "        self.l3 = Linear(8,2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = self.l2(x)\n",
    "        x = self.l3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(data=[[24.89003742 19.12943119]], grad=[[0. 0.]], trainable=True)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n(Tensor.from_numpy(np.random.rand(1, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (l1): Linear(in_features=5, out_features=6, bias=True)\n",
      "  (l2): Linear(in_features=6, out_features=8, bias=True)\n",
      "  (l3): Linear(in_features=8, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
