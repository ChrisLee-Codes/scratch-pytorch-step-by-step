{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4 线性模型和全连接神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本节，我们会介绍一种最基本的神经网络模型，全连接神经网络，其实在之前的几节，我们所实现的就是全连接神经网络，但是在本节我们会用pytorch的风格实现Module类，实现更方便的构建模型的函数，同时我们会介绍何为欠拟合，过拟合，以及一些消除欠拟合过拟合的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们首先把我们在张量这几节中实现的内容放到一个py文件中，方便我们之后的调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mytorch import Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们先实现Module类，这个类会是所有模型的夫类，主要实现了模型结构的定义，参数的初始化，同时记录和追踪模型的参数变化，当你没有定义模型前向传播的方法的时候，会报错，因为python中没有借口，我们用raise来表示，让每个子类保证实现了forward方法，同时我们希望这个类的实例被调用时，自带运行forward来求解，所以实现了\\_\\_call\\_\\_方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module:\n",
    "    def __init__(self):\n",
    "        self._parameters = {}\n",
    "        self._modules = {}\n",
    "    def forward(self, *input):\n",
    "        raise NotImplementedError\n",
    "    def __call__(self, *input):\n",
    "        return self.forward(*input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们来实现一个简单的线性模型，测试我们的Module类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class Linear(Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.w = Tensor.from_numpy(np.random.rand(in_features, out_features))\n",
    "        self.b = Tensor.from_numpy(np.random.rand(1, out_features))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x*self.w+self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(data=[[3.42376874 3.12571958 2.25732465 2.44523259 2.78703212]], grad=[[0. 0. 0. 0. 0.]], trainable=True)\n"
     ]
    }
   ],
   "source": [
    "in_features = 10\n",
    "out_features = 5\n",
    "\n",
    "linear_layer = Linear(in_features, out_features)\n",
    "x = Tensor.from_numpy(np.random.rand(1, in_features))\n",
    "output = linear_layer(x)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们希望实现named_parameters方法，这个方法会记录这个模型的各层的形状和数值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\_\\_setattr\\_\\_ 是一个特殊方法（或称魔术方法）在 Python 中，用于拦截对对象属性的赋值操作。当你试图给对象的一个属性赋值时，这个方法会被自动调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Value must be positive",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, value)\n\u001b[1;32m     10\u001b[0m obj \u001b[38;5;241m=\u001b[39m PositiveNumber(\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m obj\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m10\u001b[39m\n",
      "Cell \u001b[0;32mIn[24], line 7\u001b[0m, in \u001b[0;36mPositiveNumber.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, value):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m value \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m----> 7\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValue must be positive\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, value)\n",
      "\u001b[0;31mValueError\u001b[0m: Value must be positive"
     ]
    }
   ],
   "source": [
    "class PositiveNumber:\n",
    "    def __init__(self, initial_value):\n",
    "        self.value = initial_value\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        if name == 'value' and value < 0:\n",
    "            raise ValueError(\"Value must be positive\")\n",
    "        object.__setattr__(self, name, value)\n",
    "\n",
    "obj = PositiveNumber(5)\n",
    "obj.value = -10  # 这会触发 ValueError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们会用\\_\\_setattr\\_\\_及时更新parameters和modules列表，然后通过调用named_parameters打印参数列表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " object.\\_\\_setattr\\_\\_(self, name, value) 用于在对象中设置一个属性。在 Python 中，当我们为一个对象设置属性时，如 self.attribute = value，实际上是在调用该对象的 \\_\\_setattr\\_\\_ 方法。但在我们自定义的 \\_\\_setattr\\_\\_ 方法中，如果直接使用 self.attribute = value，这会再次触发 \\_\\_setattr\\_\\_，从而导致无限递归。为了避免这种情况，在自定义的 \\_\\_setattr\\_\\_ 方法中设置属性时，我们应该使用基类（在这种情况下是 object 类）的 \\_\\_setattr\\_\\_ 方法。这样做可以直接在对象上设置属性，而不会再次触发 \\_\\_setattr\\_\\_。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module:\n",
    "    def __init__(self):\n",
    "        self._parameters = {}\n",
    "        self._modules = {}\n",
    "\n",
    "    def forward(self, *input):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __call__(self, *input):\n",
    "        return self.forward(*input)\n",
    "\n",
    "    def named_parameters(self, memo=None, prefix=''):\n",
    "        if memo is None:\n",
    "            memo = set()\n",
    "\n",
    "        for name, param in self._parameters.items():\n",
    "            if param not in memo:\n",
    "                memo.add(param)\n",
    "                yield prefix + name, param\n",
    "\n",
    "        for name, mod in self._modules.items():\n",
    "            submodule_prefix = prefix + name + '.'\n",
    "            for name, param in mod.named_parameters(memo, submodule_prefix):\n",
    "                yield name, param\n",
    "\n",
    "    def add_module(self, name, module):\n",
    "        if not isinstance(module, Module) and module is not None:\n",
    "            raise TypeError(\"{} is not a Module subclass\".format(type(module)))\n",
    "        self._modules[name] = module\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        if isinstance(value, Tensor):\n",
    "            object.__setattr__(self, name, value)  # 先设置属性\n",
    "            self._parameters[name] = value          # 然后添加到参数字典中\n",
    "        elif isinstance(value, Module):\n",
    "            self.add_module(name, value)\n",
    "        else:\n",
    "            object.__setattr__(self, name, value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们再来测试一下Linear这个类的参数列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.w = Tensor.from_numpy(np.random.rand(in_features, out_features))\n",
    "        self.b = Tensor.from_numpy(np.random.rand(1, out_features))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x*self.w+self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w Tensor(data=[[0.28560691 0.8672992  0.88595457 0.11899527 0.80321621]\n",
      " [0.33203469 0.50307607 0.952864   0.36840301 0.2706384 ]\n",
      " [0.97381182 0.42024134 0.49264617 0.38794506 0.59529725]\n",
      " [0.08387362 0.30237794 0.26447564 0.93845391 0.16128597]\n",
      " [0.40830442 0.53959658 0.50127377 0.21927836 0.40006681]\n",
      " [0.58827379 0.74123641 0.43745427 0.13590099 0.01242012]\n",
      " [0.43069382 0.59793469 0.20412198 0.08868851 0.90757201]\n",
      " [0.90974848 0.84735987 0.02955181 0.62218034 0.69052233]\n",
      " [0.86024293 0.16520478 0.07021213 0.7879401  0.93634434]\n",
      " [0.51618515 0.21954381 0.40886429 0.09486535 0.58629152]], grad=[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]], trainable=True)\n",
      "b Tensor(data=[[0.53476514 0.53942268 0.36438901 0.44903074 0.13865316]], grad=[[0. 0. 0. 0. 0.]], trainable=True)\n"
     ]
    }
   ],
   "source": [
    "for name, parameter in linear_layer.named_parameters():\n",
    "    print(name, parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module()\n"
     ]
    }
   ],
   "source": [
    "print(linear_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，我们完成\\_\\_repr\\_\\_方法，来自动打印模型的网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module:\n",
    "    def __init__(self):\n",
    "        self._parameters = {}\n",
    "        self._modules = {}\n",
    "\n",
    "    def forward(self, *input):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __call__(self, *input):\n",
    "        return self.forward(*input)\n",
    "\n",
    "    def named_parameters(self, memo=None, prefix=''):\n",
    "        if memo is None:\n",
    "            memo = set()\n",
    "\n",
    "        for name, param in self._parameters.items():\n",
    "            if param not in memo:\n",
    "                memo.add(param)\n",
    "                yield prefix + name, param\n",
    "\n",
    "        for name, mod in self._modules.items():\n",
    "            submodule_prefix = prefix + name + '.'\n",
    "            for name, param in mod.named_parameters(memo, submodule_prefix):\n",
    "                yield name, param\n",
    "\n",
    "    def add_module(self, name, module):\n",
    "        if not isinstance(module, Module) and module is not None:\n",
    "            raise TypeError(\"{} is not a Module subclass\".format(type(module)))\n",
    "        self._modules[name] = module\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        if isinstance(value, Tensor):\n",
    "            object.__setattr__(self, name, value)  # 先设置属性\n",
    "            self._parameters[name] = value          # 然后添加到参数字典中\n",
    "        elif isinstance(value, Module):\n",
    "            object.__setattr__(self, name, value)\n",
    "            self.add_module(name, value)\n",
    "        else:\n",
    "            object.__setattr__(self, name, value)\n",
    "\n",
    "    def __repr__(self):\n",
    "        lines = [self.__class__.__name__ + '(']\n",
    "        for name, module in self._modules.items():\n",
    "            mod_str = repr(module).replace('\\n', '\\n  ')\n",
    "            lines.append(f\"  ({name}): {mod_str}\")\n",
    "        lines.append(')')\n",
    "        return '\\n'.join(lines)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们再对Linear类进行简单的修改，让其变成我们的标准模型类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Module):\n",
    "    def __init__(self, in_features, out_features, bias = True):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.bias = bias\n",
    "        self.w = Tensor.from_numpy(np.random.rand(in_features, out_features))\n",
    "        if bias:\n",
    "            self.b = Tensor.from_numpy(np.random.rand(1, out_features))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x*self.w+self.b if self.bias else x*self.w\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Linear(in_features={self.in_features}, out_features={self.out_features}, bias={self.bias})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = Linear(5,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(data=[[0.81330898 1.05057424 1.38959737 1.19471005 1.97466068 1.53463671]], grad=[[0. 0. 0. 0. 0. 0.]], trainable=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l(Tensor.from_numpy(np.random.rand(1, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=5, out_features=6, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = Linear(5,6)\n",
    "        self.l2 = Linear(6,8)\n",
    "        self.l3 = Linear(8,2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = x.relu()\n",
    "        x = self.l2(x)\n",
    "        x = x.relu()\n",
    "        x = self.l3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(data=[[12.79896658 18.67358734]], grad=[[0. 0.]], trainable=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(Tensor.from_numpy(np.random.rand(1, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (l1): Linear(in_features=5, out_features=6, bias=True)\n",
      "  (l2): Linear(in_features=6, out_features=8, bias=True)\n",
      "  (l3): Linear(in_features=8, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，让我们摩饭pytorch风格，实现MSELoss类做一个收尾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSELoss(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        loss = 0\n",
    "        for i in range(len(target)):\n",
    "            loss += (pred[i] - target[i]) ** 2\n",
    "        return loss/len(target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们实现随机批次类，我们会在每个epoch开始的时候随机打乱整个数据集，再按批次大小从中取数，知道取完再开始下一个循环的随机打乱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchSampler:\n",
    "    def __init__(self, train_x, train_y, batch_size):\n",
    "        self.train_x = train_x\n",
    "        self.train_y = train_y\n",
    "        self.batch_size = batch_size\n",
    "        self.indices = np.arange(len(self.train_x))\n",
    "        np.random.shuffle(self.indices)  # Shuffle at the start\n",
    "        self.current_index = 0\n",
    "\n",
    "    def next_batch(self):\n",
    "        if self.current_index + self.batch_size > len(self.train_x):\n",
    "            # Reshuffle the indices and reset the current index\n",
    "            np.random.shuffle(self.indices)\n",
    "            self.current_index = 0\n",
    "\n",
    "        batch_indices = self.indices[self.current_index:self.current_index + self.batch_size]\n",
    "        self.current_index += self.batch_size\n",
    "        return self.train_x[batch_indices], self.train_y[batch_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，让我们简单测试一下我们的程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    return 4*x*x - 5\n",
    "\n",
    "import numpy as np\n",
    "x_values = np.linspace(-10, 10, 100)\n",
    "y_values = func(x_values)\n",
    "\n",
    "# Randomly choosing training data\n",
    "random_indices = np.random.choice(len(x_values), size=80, replace=False)\n",
    "train_x = x_values[random_indices]\n",
    "train_y = y_values[random_indices]\n",
    "\n",
    "# The remaining data can be considered as the testing dataset\n",
    "test_x = np.delete(x_values, random_indices)\n",
    "test_y = np.delete(y_values, random_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = Linear(1,10)\n",
    "        self.l2 = Linear(10,1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = x.relu()\n",
    "        x = self.l2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(data=[[24.96495613]], grad=[[0.]], trainable=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/30000, Loss: Tensor(data=[[26729.37141054]], grad=0, trainable=True)\n",
      "Epoch 100/30000, Loss: Tensor(data=[[25864.72083901]], grad=0, trainable=True)\n",
      "Epoch 200/30000, Loss: Tensor(data=[[24781.41256319]], grad=0, trainable=True)\n",
      "Epoch 300/30000, Loss: Tensor(data=[[23525.79243365]], grad=0, trainable=True)\n",
      "Epoch 400/30000, Loss: Tensor(data=[[22167.15960628]], grad=0, trainable=True)\n",
      "Epoch 500/30000, Loss: Tensor(data=[[20785.49761644]], grad=0, trainable=True)\n",
      "Epoch 600/30000, Loss: Tensor(data=[[19457.35929128]], grad=0, trainable=True)\n",
      "Epoch 700/30000, Loss: Tensor(data=[[18242.58115979]], grad=0, trainable=True)\n",
      "Epoch 800/30000, Loss: Tensor(data=[[17174.78401135]], grad=0, trainable=True)\n",
      "Epoch 900/30000, Loss: Tensor(data=[[16258.30128231]], grad=0, trainable=True)\n",
      "Epoch 1000/30000, Loss: Tensor(data=[[15471.91651013]], grad=0, trainable=True)\n",
      "Epoch 1100/30000, Loss: Tensor(data=[[14779.9219655]], grad=0, trainable=True)\n",
      "Epoch 1200/30000, Loss: Tensor(data=[[14144.70130823]], grad=0, trainable=True)\n",
      "Epoch 1300/30000, Loss: Tensor(data=[[13536.76105437]], grad=0, trainable=True)\n",
      "Epoch 1400/30000, Loss: Tensor(data=[[12938.33797277]], grad=0, trainable=True)\n",
      "Epoch 1500/30000, Loss: Tensor(data=[[12341.34242529]], grad=0, trainable=True)\n",
      "Epoch 1600/30000, Loss: Tensor(data=[[11744.05429364]], grad=0, trainable=True)\n",
      "Epoch 1700/30000, Loss: Tensor(data=[[11148.30668041]], grad=0, trainable=True)\n",
      "Epoch 1800/30000, Loss: Tensor(data=[[10556.89351682]], grad=0, trainable=True)\n",
      "Epoch 1900/30000, Loss: Tensor(data=[[9972.80557163]], grad=0, trainable=True)\n",
      "Epoch 2000/30000, Loss: Tensor(data=[[9399.24584922]], grad=0, trainable=True)\n",
      "Epoch 2100/30000, Loss: Tensor(data=[[8839.0767975]], grad=0, trainable=True)\n",
      "Epoch 2200/30000, Loss: Tensor(data=[[8295.06619333]], grad=0, trainable=True)\n",
      "Epoch 2300/30000, Loss: Tensor(data=[[7769.70779418]], grad=0, trainable=True)\n",
      "Epoch 2400/30000, Loss: Tensor(data=[[7265.09233659]], grad=0, trainable=True)\n",
      "Epoch 2500/30000, Loss: Tensor(data=[[6783.32930845]], grad=0, trainable=True)\n",
      "Epoch 2600/30000, Loss: Tensor(data=[[6325.79221572]], grad=0, trainable=True)\n",
      "Epoch 2700/30000, Loss: Tensor(data=[[5894.14335414]], grad=0, trainable=True)\n",
      "Epoch 2800/30000, Loss: Tensor(data=[[5489.39196716]], grad=0, trainable=True)\n",
      "Epoch 2900/30000, Loss: Tensor(data=[[5112.22808451]], grad=0, trainable=True)\n",
      "Epoch 3000/30000, Loss: Tensor(data=[[4762.84111355]], grad=0, trainable=True)\n",
      "Epoch 3100/30000, Loss: Tensor(data=[[4441.39766356]], grad=0, trainable=True)\n",
      "Epoch 3200/30000, Loss: Tensor(data=[[4147.71838103]], grad=0, trainable=True)\n",
      "Epoch 3300/30000, Loss: Tensor(data=[[3881.3367767]], grad=0, trainable=True)\n",
      "Epoch 3400/30000, Loss: Tensor(data=[[3641.62006766]], grad=0, trainable=True)\n",
      "Epoch 3500/30000, Loss: Tensor(data=[[3427.12036502]], grad=0, trainable=True)\n",
      "Epoch 3600/30000, Loss: Tensor(data=[[3236.23003079]], grad=0, trainable=True)\n",
      "Epoch 3700/30000, Loss: Tensor(data=[[3067.61247289]], grad=0, trainable=True)\n",
      "Epoch 3800/30000, Loss: Tensor(data=[[2920.02324874]], grad=0, trainable=True)\n",
      "Epoch 3900/30000, Loss: Tensor(data=[[2790.99495071]], grad=0, trainable=True)\n",
      "Epoch 4000/30000, Loss: Tensor(data=[[2678.2728507]], grad=0, trainable=True)\n",
      "Epoch 4100/30000, Loss: Tensor(data=[[2580.13602178]], grad=0, trainable=True)\n",
      "Epoch 4200/30000, Loss: Tensor(data=[[2494.50486379]], grad=0, trainable=True)\n",
      "Epoch 4300/30000, Loss: Tensor(data=[[2419.46920346]], grad=0, trainable=True)\n",
      "Epoch 4400/30000, Loss: Tensor(data=[[2353.05480767]], grad=0, trainable=True)\n",
      "Epoch 4500/30000, Loss: Tensor(data=[[2293.65999033]], grad=0, trainable=True)\n",
      "Epoch 4600/30000, Loss: Tensor(data=[[2239.5874116]], grad=0, trainable=True)\n",
      "Epoch 4700/30000, Loss: Tensor(data=[[2189.79829184]], grad=0, trainable=True)\n",
      "Epoch 4800/30000, Loss: Tensor(data=[[2143.62759926]], grad=0, trainable=True)\n",
      "Epoch 4900/30000, Loss: Tensor(data=[[2099.85584326]], grad=0, trainable=True)\n",
      "Epoch 5000/30000, Loss: Tensor(data=[[2057.78585927]], grad=0, trainable=True)\n",
      "Epoch 5100/30000, Loss: Tensor(data=[[2017.16718655]], grad=0, trainable=True)\n",
      "Epoch 5200/30000, Loss: Tensor(data=[[1977.75607306]], grad=0, trainable=True)\n",
      "Epoch 5300/30000, Loss: Tensor(data=[[1939.208309]], grad=0, trainable=True)\n",
      "Epoch 5400/30000, Loss: Tensor(data=[[1901.42470464]], grad=0, trainable=True)\n",
      "Epoch 5500/30000, Loss: Tensor(data=[[1864.37767228]], grad=0, trainable=True)\n",
      "Epoch 5600/30000, Loss: Tensor(data=[[1828.26562279]], grad=0, trainable=True)\n",
      "Epoch 5700/30000, Loss: Tensor(data=[[1792.99902099]], grad=0, trainable=True)\n",
      "Epoch 5800/30000, Loss: Tensor(data=[[1758.54294627]], grad=0, trainable=True)\n",
      "Epoch 5900/30000, Loss: Tensor(data=[[1725.04721873]], grad=0, trainable=True)\n",
      "Epoch 6000/30000, Loss: Tensor(data=[[1692.49014309]], grad=0, trainable=True)\n",
      "Epoch 6100/30000, Loss: Tensor(data=[[1660.86977133]], grad=0, trainable=True)\n",
      "Epoch 6200/30000, Loss: Tensor(data=[[1630.27047133]], grad=0, trainable=True)\n",
      "Epoch 6300/30000, Loss: Tensor(data=[[1600.64092443]], grad=0, trainable=True)\n",
      "Epoch 6400/30000, Loss: Tensor(data=[[1571.98720801]], grad=0, trainable=True)\n",
      "Epoch 6500/30000, Loss: Tensor(data=[[1544.37814586]], grad=0, trainable=True)\n",
      "Epoch 6600/30000, Loss: Tensor(data=[[1517.85176787]], grad=0, trainable=True)\n",
      "Epoch 6700/30000, Loss: Tensor(data=[[1492.31227818]], grad=0, trainable=True)\n",
      "Epoch 6800/30000, Loss: Tensor(data=[[1467.74563869]], grad=0, trainable=True)\n",
      "Epoch 6900/30000, Loss: Tensor(data=[[1444.07324876]], grad=0, trainable=True)\n",
      "Epoch 7000/30000, Loss: Tensor(data=[[1421.30227051]], grad=0, trainable=True)\n",
      "Epoch 7100/30000, Loss: Tensor(data=[[1399.29542883]], grad=0, trainable=True)\n",
      "Epoch 7200/30000, Loss: Tensor(data=[[1378.0636119]], grad=0, trainable=True)\n",
      "Epoch 7300/30000, Loss: Tensor(data=[[1357.5164857]], grad=0, trainable=True)\n",
      "Epoch 7400/30000, Loss: Tensor(data=[[1337.57977527]], grad=0, trainable=True)\n",
      "Epoch 7500/30000, Loss: Tensor(data=[[1318.23994985]], grad=0, trainable=True)\n",
      "Epoch 7600/30000, Loss: Tensor(data=[[1299.52856894]], grad=0, trainable=True)\n",
      "Epoch 7700/30000, Loss: Tensor(data=[[1281.34784755]], grad=0, trainable=True)\n",
      "Epoch 7800/30000, Loss: Tensor(data=[[1263.71437277]], grad=0, trainable=True)\n",
      "Epoch 7900/30000, Loss: Tensor(data=[[1246.57360731]], grad=0, trainable=True)\n",
      "Epoch 8000/30000, Loss: Tensor(data=[[1229.96901078]], grad=0, trainable=True)\n",
      "Epoch 8100/30000, Loss: Tensor(data=[[1213.80350304]], grad=0, trainable=True)\n",
      "Epoch 8200/30000, Loss: Tensor(data=[[1198.09896667]], grad=0, trainable=True)\n",
      "Epoch 8300/30000, Loss: Tensor(data=[[1182.84185628]], grad=0, trainable=True)\n",
      "Epoch 8400/30000, Loss: Tensor(data=[[1167.9970983]], grad=0, trainable=True)\n",
      "Epoch 8500/30000, Loss: Tensor(data=[[1153.54706397]], grad=0, trainable=True)\n",
      "Epoch 8600/30000, Loss: Tensor(data=[[1139.4888349]], grad=0, trainable=True)\n",
      "Epoch 8700/30000, Loss: Tensor(data=[[1125.68304569]], grad=0, trainable=True)\n",
      "Epoch 8800/30000, Loss: Tensor(data=[[1112.18589594]], grad=0, trainable=True)\n",
      "Epoch 8900/30000, Loss: Tensor(data=[[1098.91806675]], grad=0, trainable=True)\n",
      "Epoch 9000/30000, Loss: Tensor(data=[[1085.75822199]], grad=0, trainable=True)\n",
      "Epoch 9100/30000, Loss: Tensor(data=[[1072.65622841]], grad=0, trainable=True)\n",
      "Epoch 9200/30000, Loss: Tensor(data=[[1059.66606479]], grad=0, trainable=True)\n",
      "Epoch 9300/30000, Loss: Tensor(data=[[1046.84011449]], grad=0, trainable=True)\n",
      "Epoch 9400/30000, Loss: Tensor(data=[[1034.28831838]], grad=0, trainable=True)\n",
      "Epoch 9500/30000, Loss: Tensor(data=[[1022.09186237]], grad=0, trainable=True)\n",
      "Epoch 9600/30000, Loss: Tensor(data=[[1010.22256502]], grad=0, trainable=True)\n",
      "Epoch 9700/30000, Loss: Tensor(data=[[998.61543223]], grad=0, trainable=True)\n",
      "Epoch 9800/30000, Loss: Tensor(data=[[987.23744201]], grad=0, trainable=True)\n",
      "Epoch 9900/30000, Loss: Tensor(data=[[976.0452816]], grad=0, trainable=True)\n",
      "Epoch 10000/30000, Loss: Tensor(data=[[964.9957609]], grad=0, trainable=True)\n",
      "Epoch 10100/30000, Loss: Tensor(data=[[954.08117737]], grad=0, trainable=True)\n",
      "Epoch 10200/30000, Loss: Tensor(data=[[943.27551467]], grad=0, trainable=True)\n",
      "Epoch 10300/30000, Loss: Tensor(data=[[932.5679901]], grad=0, trainable=True)\n",
      "Epoch 10400/30000, Loss: Tensor(data=[[921.94283221]], grad=0, trainable=True)\n",
      "Epoch 10500/30000, Loss: Tensor(data=[[911.37516249]], grad=0, trainable=True)\n",
      "Epoch 10600/30000, Loss: Tensor(data=[[900.84725963]], grad=0, trainable=True)\n",
      "Epoch 10700/30000, Loss: Tensor(data=[[890.34872001]], grad=0, trainable=True)\n",
      "Epoch 10800/30000, Loss: Tensor(data=[[879.86436796]], grad=0, trainable=True)\n",
      "Epoch 10900/30000, Loss: Tensor(data=[[869.37470753]], grad=0, trainable=True)\n",
      "Epoch 11000/30000, Loss: Tensor(data=[[858.86443225]], grad=0, trainable=True)\n",
      "Epoch 11100/30000, Loss: Tensor(data=[[848.32120094]], grad=0, trainable=True)\n",
      "Epoch 11200/30000, Loss: Tensor(data=[[837.73380695]], grad=0, trainable=True)\n",
      "Epoch 11300/30000, Loss: Tensor(data=[[827.08803696]], grad=0, trainable=True)\n",
      "Epoch 11400/30000, Loss: Tensor(data=[[816.36537497]], grad=0, trainable=True)\n",
      "Epoch 11500/30000, Loss: Tensor(data=[[805.55533359]], grad=0, trainable=True)\n",
      "Epoch 11600/30000, Loss: Tensor(data=[[794.64586382]], grad=0, trainable=True)\n",
      "Epoch 11700/30000, Loss: Tensor(data=[[783.62990955]], grad=0, trainable=True)\n",
      "Epoch 11800/30000, Loss: Tensor(data=[[772.49962162]], grad=0, trainable=True)\n",
      "Epoch 11900/30000, Loss: Tensor(data=[[761.24265415]], grad=0, trainable=True)\n",
      "Epoch 12000/30000, Loss: Tensor(data=[[749.85451474]], grad=0, trainable=True)\n",
      "Epoch 12100/30000, Loss: Tensor(data=[[738.32735275]], grad=0, trainable=True)\n",
      "Epoch 12200/30000, Loss: Tensor(data=[[726.63292127]], grad=0, trainable=True)\n",
      "Epoch 12300/30000, Loss: Tensor(data=[[714.77937254]], grad=0, trainable=True)\n",
      "Epoch 12400/30000, Loss: Tensor(data=[[702.77036995]], grad=0, trainable=True)\n",
      "Epoch 12500/30000, Loss: Tensor(data=[[690.61739485]], grad=0, trainable=True)\n",
      "Epoch 12600/30000, Loss: Tensor(data=[[678.3375381]], grad=0, trainable=True)\n",
      "Epoch 12700/30000, Loss: Tensor(data=[[665.95232675]], grad=0, trainable=True)\n",
      "Epoch 12800/30000, Loss: Tensor(data=[[653.48658215]], grad=0, trainable=True)\n",
      "Epoch 12900/30000, Loss: Tensor(data=[[640.96813021]], grad=0, trainable=True)\n",
      "Epoch 13000/30000, Loss: Tensor(data=[[628.31401652]], grad=0, trainable=True)\n",
      "Epoch 13100/30000, Loss: Tensor(data=[[615.61847427]], grad=0, trainable=True)\n",
      "Epoch 13200/30000, Loss: Tensor(data=[[602.92562355]], grad=0, trainable=True)\n",
      "Epoch 13300/30000, Loss: Tensor(data=[[590.26821017]], grad=0, trainable=True)\n",
      "Epoch 13400/30000, Loss: Tensor(data=[[577.68032954]], grad=0, trainable=True)\n",
      "Epoch 13500/30000, Loss: Tensor(data=[[565.19018425]], grad=0, trainable=True)\n",
      "Epoch 13600/30000, Loss: Tensor(data=[[552.82757024]], grad=0, trainable=True)\n",
      "Epoch 13700/30000, Loss: Tensor(data=[[540.45680627]], grad=0, trainable=True)\n",
      "Epoch 13800/30000, Loss: Tensor(data=[[528.17108668]], grad=0, trainable=True)\n",
      "Epoch 13900/30000, Loss: Tensor(data=[[516.04819516]], grad=0, trainable=True)\n",
      "Epoch 14000/30000, Loss: Tensor(data=[[504.10773212]], grad=0, trainable=True)\n",
      "Epoch 14100/30000, Loss: Tensor(data=[[492.37202419]], grad=0, trainable=True)\n",
      "Epoch 14200/30000, Loss: Tensor(data=[[480.86279958]], grad=0, trainable=True)\n",
      "Epoch 14300/30000, Loss: Tensor(data=[[469.45614331]], grad=0, trainable=True)\n",
      "Epoch 14400/30000, Loss: Tensor(data=[[457.86953145]], grad=0, trainable=True)\n",
      "Epoch 14500/30000, Loss: Tensor(data=[[446.16724109]], grad=0, trainable=True)\n",
      "Epoch 14600/30000, Loss: Tensor(data=[[434.66502816]], grad=0, trainable=True)\n",
      "Epoch 14700/30000, Loss: Tensor(data=[[423.54891623]], grad=0, trainable=True)\n",
      "Epoch 14800/30000, Loss: Tensor(data=[[412.69963896]], grad=0, trainable=True)\n",
      "Epoch 14900/30000, Loss: Tensor(data=[[402.27842241]], grad=0, trainable=True)\n",
      "Epoch 15000/30000, Loss: Tensor(data=[[392.12515804]], grad=0, trainable=True)\n",
      "Epoch 15100/30000, Loss: Tensor(data=[[381.80265344]], grad=0, trainable=True)\n",
      "Epoch 15200/30000, Loss: Tensor(data=[[371.86125963]], grad=0, trainable=True)\n",
      "Epoch 15300/30000, Loss: Tensor(data=[[362.28646052]], grad=0, trainable=True)\n",
      "Epoch 15400/30000, Loss: Tensor(data=[[353.02509844]], grad=0, trainable=True)\n",
      "Epoch 15500/30000, Loss: Tensor(data=[[344.06753128]], grad=0, trainable=True)\n",
      "Epoch 15600/30000, Loss: Tensor(data=[[335.41286684]], grad=0, trainable=True)\n",
      "Epoch 15700/30000, Loss: Tensor(data=[[327.07418168]], grad=0, trainable=True)\n",
      "Epoch 15800/30000, Loss: Tensor(data=[[318.57747878]], grad=0, trainable=True)\n",
      "Epoch 15900/30000, Loss: Tensor(data=[[310.20170372]], grad=0, trainable=True)\n",
      "Epoch 16000/30000, Loss: Tensor(data=[[302.12214981]], grad=0, trainable=True)\n",
      "Epoch 16100/30000, Loss: Tensor(data=[[294.34258153]], grad=0, trainable=True)\n",
      "Epoch 16200/30000, Loss: Tensor(data=[[286.8552024]], grad=0, trainable=True)\n",
      "Epoch 16300/30000, Loss: Tensor(data=[[279.64910911]], grad=0, trainable=True)\n",
      "Epoch 16400/30000, Loss: Tensor(data=[[272.75254497]], grad=0, trainable=True)\n",
      "Epoch 16500/30000, Loss: Tensor(data=[[265.90681494]], grad=0, trainable=True)\n",
      "Epoch 16600/30000, Loss: Tensor(data=[[258.82251992]], grad=0, trainable=True)\n",
      "Epoch 16700/30000, Loss: Tensor(data=[[252.03346926]], grad=0, trainable=True)\n",
      "Epoch 16800/30000, Loss: Tensor(data=[[245.54048921]], grad=0, trainable=True)\n",
      "Epoch 16900/30000, Loss: Tensor(data=[[239.34327183]], grad=0, trainable=True)\n",
      "Epoch 17000/30000, Loss: Tensor(data=[[233.44129092]], grad=0, trainable=True)\n",
      "Epoch 17100/30000, Loss: Tensor(data=[[227.83289873]], grad=0, trainable=True)\n",
      "Epoch 17200/30000, Loss: Tensor(data=[[222.51636238]], grad=0, trainable=True)\n",
      "Epoch 17300/30000, Loss: Tensor(data=[[216.94980364]], grad=0, trainable=True)\n",
      "Epoch 17400/30000, Loss: Tensor(data=[[211.24801001]], grad=0, trainable=True)\n",
      "Epoch 17500/30000, Loss: Tensor(data=[[205.8381046]], grad=0, trainable=True)\n",
      "Epoch 17600/30000, Loss: Tensor(data=[[200.71586667]], grad=0, trainable=True)\n",
      "Epoch 17700/30000, Loss: Tensor(data=[[195.87702167]], grad=0, trainable=True)\n",
      "Epoch 17800/30000, Loss: Tensor(data=[[191.31342344]], grad=0, trainable=True)\n",
      "Epoch 17900/30000, Loss: Tensor(data=[[186.99271335]], grad=0, trainable=True)\n",
      "Epoch 18000/30000, Loss: Tensor(data=[[182.94852546]], grad=0, trainable=True)\n",
      "Epoch 18100/30000, Loss: Tensor(data=[[179.17095288]], grad=0, trainable=True)\n",
      "Epoch 18200/30000, Loss: Tensor(data=[[175.65150383]], grad=0, trainable=True)\n",
      "Epoch 18300/30000, Loss: Tensor(data=[[172.3779312]], grad=0, trainable=True)\n",
      "Epoch 18400/30000, Loss: Tensor(data=[[169.34873888]], grad=0, trainable=True)\n",
      "Epoch 18500/30000, Loss: Tensor(data=[[166.55256665]], grad=0, trainable=True)\n",
      "Epoch 18600/30000, Loss: Tensor(data=[[163.97977334]], grad=0, trainable=True)\n",
      "Epoch 18700/30000, Loss: Tensor(data=[[161.62039509]], grad=0, trainable=True)\n",
      "Epoch 18800/30000, Loss: Tensor(data=[[159.46392088]], grad=0, trainable=True)\n",
      "Epoch 18900/30000, Loss: Tensor(data=[[157.49945239]], grad=0, trainable=True)\n",
      "Epoch 19000/30000, Loss: Tensor(data=[[155.71538357]], grad=0, trainable=True)\n",
      "Epoch 19100/30000, Loss: Tensor(data=[[153.79276618]], grad=0, trainable=True)\n",
      "Epoch 19200/30000, Loss: Tensor(data=[[151.25401149]], grad=0, trainable=True)\n",
      "Epoch 19300/30000, Loss: Tensor(data=[[148.9459093]], grad=0, trainable=True)\n",
      "Epoch 19400/30000, Loss: Tensor(data=[[146.8539419]], grad=0, trainable=True)\n",
      "Epoch 19500/30000, Loss: Tensor(data=[[144.96073283]], grad=0, trainable=True)\n",
      "Epoch 19600/30000, Loss: Tensor(data=[[143.25034523]], grad=0, trainable=True)\n",
      "Epoch 19700/30000, Loss: Tensor(data=[[141.70857379]], grad=0, trainable=True)\n",
      "Epoch 19800/30000, Loss: Tensor(data=[[140.31681732]], grad=0, trainable=True)\n",
      "Epoch 19900/30000, Loss: Tensor(data=[[139.06650991]], grad=0, trainable=True)\n",
      "Epoch 20000/30000, Loss: Tensor(data=[[137.94746307]], grad=0, trainable=True)\n",
      "Epoch 20100/30000, Loss: Tensor(data=[[136.94731262]], grad=0, trainable=True)\n",
      "Epoch 20200/30000, Loss: Tensor(data=[[135.84281549]], grad=0, trainable=True)\n",
      "Epoch 20300/30000, Loss: Tensor(data=[[133.9372124]], grad=0, trainable=True)\n",
      "Epoch 20400/30000, Loss: Tensor(data=[[132.256781]], grad=0, trainable=True)\n",
      "Epoch 20500/30000, Loss: Tensor(data=[[130.7802479]], grad=0, trainable=True)\n",
      "Epoch 20600/30000, Loss: Tensor(data=[[129.48377017]], grad=0, trainable=True)\n",
      "Epoch 20700/30000, Loss: Tensor(data=[[128.34603207]], grad=0, trainable=True)\n",
      "Epoch 20800/30000, Loss: Tensor(data=[[127.34737106]], grad=0, trainable=True)\n",
      "Epoch 20900/30000, Loss: Tensor(data=[[126.47027889]], grad=0, trainable=True)\n",
      "Epoch 21000/30000, Loss: Tensor(data=[[125.69854589]], grad=0, trainable=True)\n",
      "Epoch 21100/30000, Loss: Tensor(data=[[125.01179271]], grad=0, trainable=True)\n",
      "Epoch 21200/30000, Loss: Tensor(data=[[124.40293987]], grad=0, trainable=True)\n",
      "Epoch 21300/30000, Loss: Tensor(data=[[123.86186379]], grad=0, trainable=True)\n",
      "Epoch 21400/30000, Loss: Tensor(data=[[123.37673996]], grad=0, trainable=True)\n",
      "Epoch 21500/30000, Loss: Tensor(data=[[122.93798974]], grad=0, trainable=True)\n",
      "Epoch 21600/30000, Loss: Tensor(data=[[121.9927509]], grad=0, trainable=True)\n",
      "Epoch 21700/30000, Loss: Tensor(data=[[120.66784991]], grad=0, trainable=True)\n",
      "Epoch 21800/30000, Loss: Tensor(data=[[119.58174839]], grad=0, trainable=True)\n",
      "Epoch 21900/30000, Loss: Tensor(data=[[118.68050022]], grad=0, trainable=True)\n",
      "Epoch 22000/30000, Loss: Tensor(data=[[117.92184561]], grad=0, trainable=True)\n",
      "Epoch 22100/30000, Loss: Tensor(data=[[117.27341948]], grad=0, trainable=True)\n",
      "Epoch 22200/30000, Loss: Tensor(data=[[116.70988919]], grad=0, trainable=True)\n",
      "Epoch 22300/30000, Loss: Tensor(data=[[116.21119291]], grad=0, trainable=True)\n",
      "Epoch 22400/30000, Loss: Tensor(data=[[115.76186063]], grad=0, trainable=True)\n",
      "Epoch 22500/30000, Loss: Tensor(data=[[115.35006078]], grad=0, trainable=True)\n",
      "Epoch 22600/30000, Loss: Tensor(data=[[114.96688866]], grad=0, trainable=True)\n",
      "Epoch 22700/30000, Loss: Tensor(data=[[114.605748]], grad=0, trainable=True)\n",
      "Epoch 22800/30000, Loss: Tensor(data=[[114.26211203]], grad=0, trainable=True)\n",
      "Epoch 22900/30000, Loss: Tensor(data=[[113.93454705]], grad=0, trainable=True)\n",
      "Epoch 23000/30000, Loss: Tensor(data=[[113.61884145]], grad=0, trainable=True)\n",
      "Epoch 23100/30000, Loss: Tensor(data=[[113.31325196]], grad=0, trainable=True)\n",
      "Epoch 23200/30000, Loss: Tensor(data=[[113.01584062]], grad=0, trainable=True)\n",
      "Epoch 23300/30000, Loss: Tensor(data=[[112.72620519]], grad=0, trainable=True)\n",
      "Epoch 23400/30000, Loss: Tensor(data=[[112.44340226]], grad=0, trainable=True)\n",
      "Epoch 23500/30000, Loss: Tensor(data=[[112.16688151]], grad=0, trainable=True)\n",
      "Epoch 23600/30000, Loss: Tensor(data=[[111.89619913]], grad=0, trainable=True)\n",
      "Epoch 23700/30000, Loss: Tensor(data=[[111.6322797]], grad=0, trainable=True)\n",
      "Epoch 23800/30000, Loss: Tensor(data=[[111.37587014]], grad=0, trainable=True)\n",
      "Epoch 23900/30000, Loss: Tensor(data=[[111.12445364]], grad=0, trainable=True)\n",
      "Epoch 24000/30000, Loss: Tensor(data=[[110.87836433]], grad=0, trainable=True)\n",
      "Epoch 24100/30000, Loss: Tensor(data=[[110.6370698]], grad=0, trainable=True)\n",
      "Epoch 24200/30000, Loss: Tensor(data=[[110.40028681]], grad=0, trainable=True)\n",
      "Epoch 24300/30000, Loss: Tensor(data=[[110.1679081]], grad=0, trainable=True)\n",
      "Epoch 24400/30000, Loss: Tensor(data=[[109.93980544]], grad=0, trainable=True)\n",
      "Epoch 24500/30000, Loss: Tensor(data=[[109.71573558]], grad=0, trainable=True)\n",
      "Epoch 24600/30000, Loss: Tensor(data=[[109.49568533]], grad=0, trainable=True)\n",
      "Epoch 24700/30000, Loss: Tensor(data=[[109.28018393]], grad=0, trainable=True)\n",
      "Epoch 24800/30000, Loss: Tensor(data=[[109.06926843]], grad=0, trainable=True)\n",
      "Epoch 24900/30000, Loss: Tensor(data=[[108.6581443]], grad=0, trainable=True)\n",
      "Epoch 25000/30000, Loss: Tensor(data=[[106.85734333]], grad=0, trainable=True)\n",
      "Epoch 25100/30000, Loss: Tensor(data=[[106.15013062]], grad=0, trainable=True)\n",
      "Epoch 25200/30000, Loss: Tensor(data=[[105.72898881]], grad=0, trainable=True)\n",
      "Epoch 25300/30000, Loss: Tensor(data=[[105.38765397]], grad=0, trainable=True)\n",
      "Epoch 25400/30000, Loss: Tensor(data=[[105.07401529]], grad=0, trainable=True)\n",
      "Epoch 25500/30000, Loss: Tensor(data=[[104.7747903]], grad=0, trainable=True)\n",
      "Epoch 25600/30000, Loss: Tensor(data=[[104.48626231]], grad=0, trainable=True)\n",
      "Epoch 25700/30000, Loss: Tensor(data=[[104.20701634]], grad=0, trainable=True)\n",
      "Epoch 25800/30000, Loss: Tensor(data=[[103.93619401]], grad=0, trainable=True)\n",
      "Epoch 25900/30000, Loss: Tensor(data=[[103.67436185]], grad=0, trainable=True)\n",
      "Epoch 26000/30000, Loss: Tensor(data=[[103.42066385]], grad=0, trainable=True)\n",
      "Epoch 26100/30000, Loss: Tensor(data=[[103.1744982]], grad=0, trainable=True)\n",
      "Epoch 26200/30000, Loss: Tensor(data=[[102.93518973]], grad=0, trainable=True)\n",
      "Epoch 26300/30000, Loss: Tensor(data=[[102.70224889]], grad=0, trainable=True)\n",
      "Epoch 26400/30000, Loss: Tensor(data=[[102.47528492]], grad=0, trainable=True)\n",
      "Epoch 26500/30000, Loss: Tensor(data=[[102.25393637]], grad=0, trainable=True)\n",
      "Epoch 26600/30000, Loss: Tensor(data=[[102.03799409]], grad=0, trainable=True)\n",
      "Epoch 26700/30000, Loss: Tensor(data=[[101.82722949]], grad=0, trainable=True)\n",
      "Epoch 26800/30000, Loss: Tensor(data=[[101.62144459]], grad=0, trainable=True)\n",
      "Epoch 26900/30000, Loss: Tensor(data=[[101.42109619]], grad=0, trainable=True)\n",
      "Epoch 27000/30000, Loss: Tensor(data=[[101.22416554]], grad=0, trainable=True)\n",
      "Epoch 27100/30000, Loss: Tensor(data=[[101.03238902]], grad=0, trainable=True)\n",
      "Epoch 27200/30000, Loss: Tensor(data=[[100.84524697]], grad=0, trainable=True)\n",
      "Epoch 27300/30000, Loss: Tensor(data=[[100.66288755]], grad=0, trainable=True)\n",
      "Epoch 27400/30000, Loss: Tensor(data=[[100.48511925]], grad=0, trainable=True)\n",
      "Epoch 27500/30000, Loss: Tensor(data=[[100.31179512]], grad=0, trainable=True)\n",
      "Epoch 27600/30000, Loss: Tensor(data=[[100.14280528]], grad=0, trainable=True)\n",
      "Epoch 27700/30000, Loss: Tensor(data=[[99.97806067]], grad=0, trainable=True)\n",
      "Epoch 27800/30000, Loss: Tensor(data=[[99.81748188]], grad=0, trainable=True)\n",
      "Epoch 27900/30000, Loss: Tensor(data=[[99.66098653]], grad=0, trainable=True)\n",
      "Epoch 28000/30000, Loss: Tensor(data=[[99.50850101]], grad=0, trainable=True)\n",
      "Epoch 28100/30000, Loss: Tensor(data=[[99.35997229]], grad=0, trainable=True)\n",
      "Epoch 28200/30000, Loss: Tensor(data=[[99.21531313]], grad=0, trainable=True)\n",
      "Epoch 28300/30000, Loss: Tensor(data=[[99.07448746]], grad=0, trainable=True)\n",
      "Epoch 28400/30000, Loss: Tensor(data=[[98.9377823]], grad=0, trainable=True)\n",
      "Epoch 28500/30000, Loss: Tensor(data=[[98.80374375]], grad=0, trainable=True)\n",
      "Epoch 28600/30000, Loss: Tensor(data=[[98.673561]], grad=0, trainable=True)\n",
      "Epoch 28700/30000, Loss: Tensor(data=[[98.54741397]], grad=0, trainable=True)\n",
      "Epoch 28800/30000, Loss: Tensor(data=[[98.42498266]], grad=0, trainable=True)\n",
      "Epoch 28900/30000, Loss: Tensor(data=[[98.30613172]], grad=0, trainable=True)\n",
      "Epoch 29000/30000, Loss: Tensor(data=[[98.19077526]], grad=0, trainable=True)\n",
      "Epoch 29100/30000, Loss: Tensor(data=[[98.07887534]], grad=0, trainable=True)\n",
      "Epoch 29200/30000, Loss: Tensor(data=[[97.97039273]], grad=0, trainable=True)\n",
      "Epoch 29300/30000, Loss: Tensor(data=[[97.86528638]], grad=0, trainable=True)\n",
      "Epoch 29400/30000, Loss: Tensor(data=[[97.76350951]], grad=0, trainable=True)\n",
      "Epoch 29500/30000, Loss: Tensor(data=[[97.66515359]], grad=0, trainable=True)\n",
      "Epoch 29600/30000, Loss: Tensor(data=[[97.57040818]], grad=0, trainable=True)\n",
      "Epoch 29700/30000, Loss: Tensor(data=[[97.4791466]], grad=0, trainable=True)\n",
      "Epoch 29800/30000, Loss: Tensor(data=[[97.39133691]], grad=0, trainable=True)\n",
      "Epoch 29900/30000, Loss: Tensor(data=[[97.30686847]], grad=0, trainable=True)\n"
     ]
    }
   ],
   "source": [
    "epoch = 30000\n",
    "t = 0\n",
    "mse_loss = MSELoss()\n",
    "for i in range(epoch):\n",
    "    loss = mse_loss([net(x) for x in train_x], train_y)\n",
    "    loss.backward()\n",
    "    t = loss.adam_opt(t, learning_rate=0.001)\n",
    "    if i % 100 == 0:\n",
    "        print(f'Epoch {i}/{epoch}, Loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw(forward_func, test_x, test_y):\n",
    "    # 创建绘图\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # 绘制 forward 函数的曲线\n",
    "    line_x = np.linspace(min(test_x), max(test_x), 100)\n",
    "    line_y = [forward_func(x).data[0][0] for x in line_x]\n",
    "    plt.plot(line_x, line_y, label=\"Forward Function\", color='blue')\n",
    "\n",
    "    # 绘制测试集的点\n",
    "    plt.scatter(test_x, test_y, label=\"Test Data\", color='red')\n",
    "\n",
    "    # 添加图例和标签\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title('Forward Function vs Test Data')\n",
    "    plt.legend()\n",
    "\n",
    "    # 显示图形\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw(net, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/30000, Loss: Tensor(data=[[1.53757469e+08]], grad=[[0.]], trainable=True)\n",
      "Epoch 100/30000, Loss: Tensor(data=[[1.2935343e+08]], grad=[[0.]], trainable=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m     loss_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m     13\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 14\u001b[0m     loss\u001b[38;5;241m.\u001b[39madam_opt(t, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_sum\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/scratch-anything/deep learning/jupyter_notebook/2. 从零开始实现_从神经元到全连接神经网络/mytorch.py:298\u001b[0m, in \u001b[0;36mTensor.adam_opt\u001b[0;34m(self, t, learning_rate, beta1, beta2, epsilon, grad_zero)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# 更新动量和速度\u001b[39;00m\n\u001b[1;32m    297\u001b[0m tensor\u001b[38;5;241m.\u001b[39mmomentum \u001b[38;5;241m=\u001b[39m beta1 \u001b[38;5;241m*\u001b[39m tensor\u001b[38;5;241m.\u001b[39mmomentum \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1) \u001b[38;5;241m*\u001b[39m tensor\u001b[38;5;241m.\u001b[39mgrad\n\u001b[0;32m--> 298\u001b[0m tensor\u001b[38;5;241m.\u001b[39mvelocity \u001b[38;5;241m=\u001b[39m beta2 \u001b[38;5;241m*\u001b[39m tensor\u001b[38;5;241m.\u001b[39mvelocity \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msquare(tensor\u001b[38;5;241m.\u001b[39mgrad)\n\u001b[1;32m    300\u001b[0m \u001b[38;5;66;03m# 计算偏差校正后的估计\u001b[39;00m\n\u001b[1;32m    301\u001b[0m m_hat \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mmomentum \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m t)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch = 30000\n",
    "batch_size = 80\n",
    "batch_sampler = BatchSampler(train_x, train_y, batch_size)\n",
    "mse_loss = MSELoss()\n",
    "t = 0\n",
    "for i in range(epoch):\n",
    "    loss_sum = 0\n",
    "    for _ in range(len(train_y)//5):\n",
    "        batch_train_x, batch_train_y = batch_sampler.next_batch()\n",
    "        pred = [net(x) for x in batch_train_x]\n",
    "        loss = mse_loss(pred, batch_train_y)\n",
    "        loss_sum += loss\n",
    "        loss.backward()\n",
    "        loss.adam_opt(t, learning_rate=0.001)\n",
    "    if i % 100 == 0:\n",
    "        print(f'Epoch {i}/{epoch}, Loss: {loss_sum}')\n",
    "    t += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
